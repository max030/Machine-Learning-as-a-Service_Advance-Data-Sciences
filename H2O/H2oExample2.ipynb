{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>2 mins 33 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.10.5.4</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>18 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_sneha_rp971x</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.751 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.0 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------\n",
       "H2O cluster uptime:         2 mins 33 secs\n",
       "H2O cluster version:        3.10.5.4\n",
       "H2O cluster version age:    18 days\n",
       "H2O cluster name:           H2O_from_python_sneha_rp971x\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.751 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "Python version:             3.6.0 final\n",
       "--------------------------  ----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# # Introduction\n",
    "# This tutorial shows how H2O [Gradient Boosted Models](https://en.wikipedia.org/wiki/Gradient_boosting) and [Random Forest](https://en.wikipedia.org/wiki/Random_forest) models can be used to do supervised classification and regression. This tutorial covers usage of H2O from Python. An R version of this tutorial will be available as well in a separate document. This file is available in plain R, R markdown, regular markdown, plain Python and iPython Notebook formats. More examples and explanations can be found in our [H2O GBM booklet](http://h2o.ai/resources/) and on our [H2O Github Repository](http://github.com/h2oai/h2o-3/).\n",
    "# \n",
    "\n",
    "# ## Task: Predicting forest cover type from cartographic variables only\n",
    "# \n",
    "# The actual forest cover type for a given observation (30 x 30 meter cell) was determined from the US Forest Service (USFS). We are using the UC Irvine Covertype dataset.\n",
    "\n",
    "# ### H2O Python Module\n",
    "# \n",
    "# Load the H2O Python module.\n",
    "\n",
    "\n",
    "\n",
    "import h2o\n",
    "import os\n",
    "\n",
    "\n",
    "# ### Start H2O\n",
    "# Start up a 1-node H2O cloud on your local machine, and allow it to use all CPU cores and up to 2GB of memory:\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "h2o.init(max_mem_size = \"2G\")             #specify max number of bytes. uses all cores by default.\n",
    "h2o.remove_all()                          #clean slate, in case cluster was already running\n",
    "\n",
    "\n",
    "# To learn more about the h2o package itself, we can use Python's builtin help() function.\n",
    "\n",
    "\n",
    "# help(h2o)\n",
    "\n",
    "\n",
    "# help() can be used on H2O functions and models. Jupyter's builtin shift-tab functionality also works\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "# help(H2OGradientBoostingEstimator)\n",
    "# help(h2o.import_file)\n",
    "\n",
    "\n",
    "# ## H2O GBM and RF\n",
    "# \n",
    "# While H2O Gradient Boosting Models and H2O Random Forest have many flexible parameters options, they were designed to be just as easy to use as the other supervised training methods in H2O. Early stopping, automatic data standardization and handling of categorical variables and missing values and adaptive learning rates (per weight) reduce the amount of parameters the user has to specify. Often, it's just the number and sizes of hidden layers, the number of epochs and the activation function and maybe some regularization techniques. \n",
    "\n",
    "# ### Getting started\n",
    "# \n",
    "# We begin by importing our data into H2OFrames, which operate similarly in function to pandas DataFrames but exist on the H2O cloud itself.  \n",
    "# \n",
    "# In this case, the H2O cluster is running on our laptops. Data files are imported by their relative locations to this notebook.\n",
    "\n",
    "\n",
    "covtype_df = h2o.import_file(os.path.realpath(\"covtype.full.csv\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We import the full covertype dataset (581k rows, 13 columns, 10 numerical, 3 categorical) and then split the data 3 ways:  \n",
    "#   \n",
    "# 60% for training  \n",
    "# 20% for validation (hyper parameter tuning)  \n",
    "# 20% for final testing  \n",
    "# \n",
    "#  We will train a data set on one set and use the others to test the validity of the model by ensuring that it can predict accurately on data the model has not been shown.  \n",
    "#  \n",
    "#  The second set will be used for validation most of the time.  \n",
    "#  \n",
    "#  The third set will be withheld until the end, to ensure that our validation accuracy is consistent with data we have never seen during the iterative process. \n",
    "\n",
    "\n",
    "#split the data as described above\n",
    "train, valid, test = covtype_df.split_frame([0.6, 0.2], seed=1234)\n",
    "\n",
    "#Prepare predictors and response columns\n",
    "covtype_X = covtype_df.col_names[:-1]     #last column is Cover_Type, our desired response variable \n",
    "covtype_y = covtype_df.col_names[-1]    \n",
    "\n",
    "\n",
    "# ### The First Random Forest\n",
    "# We build our first model with the following parameters\n",
    "# \n",
    "# **model_id:** Not required, but allows us to easily find our model in the [Flow](http://localhost:54321/) interface  \n",
    "# **ntrees:** Maximum number of trees used by the random forest. Default value is 50. We can afford to increase this, as our early-stopping criterion will decide when the random forest is sufficiently accurate.  \n",
    "# **stopping_rounds:** Stopping criterion described above. Stops fitting new trees when 2-tree rolling average is within 0.001 (default) of the two prior rolling averages. Can be thought of as a convergence setting.  \n",
    "# **score_each_teration:** predict against training and validation for each tree. Default will skip several.  \n",
    "# **seed:** set the randomization seed so we can reproduce results\n",
    "# \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_v1 = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_covType_v1\",\n",
    "    ntrees=200,\n",
    "    stopping_rounds=2,\n",
    "    score_each_iteration=True,\n",
    "    seed=1000000)\n",
    "\n",
    "\n",
    "# ### Model Construction\n",
    "# H2O in Python is designed to be very similar in look and feel to to scikit-learn. Models are initialized individually with desired or default parameters and then trained on data.  \n",
    "# \n",
    "# **Note that the below example uses model.train() as opposed the traditional model.fit()**  \n",
    "# This is because h2o-py takes column indices for the feature and response columns AND the whole data frame, while scikit-learn takes in a feature frame and a response frame.\n",
    "# \n",
    "# H2O supports model.fit() so that it can be incorporated into a scikit-learn pipeline, but we advise using train() in all other cases.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |████"
     ]
    }
   ],
   "source": [
    "rf_v1.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)\n",
    "\n",
    "\n",
    "# Note that the progress bar does not behave linearly. H2O estimates completion time initially based on the number of epochs specified. However, convergence can allow for early stops, in which case the bar jumps to 100%.\n",
    "# \n",
    "# We can view information about the model in [Flow](http://localhost:54321/) or within Python. To find more information in Flow, enter `getModel \"rf_covType_v1\"` into a cell and run in place pressing Ctrl-Enter. Alternatively, you can click on the Models tab, select List All Models, and click on the model named \"rf_covType_v1\" as specified in our model construction above.\n",
    "# \n",
    "# In Python, we can call the model itself to get an overview of its stats.\n",
    "\n",
    "\n",
    "\n",
    "rf_v1\n",
    "\n",
    "\n",
    "# To look at validation statistics, we can use the scoring history function.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_v1.score_history()\n",
    "\n",
    "\n",
    "# Here we can see the hit ratio table.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "rf_v1.hit_ratio_table(valid=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# ### Now for GBM\n",
    "# \n",
    "# First we will use all default settings, then make some changes to improve our predictions.\n",
    "\n",
    "\n",
    "\n",
    "gbm_v1 = H2OGradientBoostingEstimator(\n",
    "    model_id=\"gbm_covType_v1\",\n",
    "    seed=2000000\n",
    ")\n",
    "gbm_v1.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2017-07-30 14:06:08</td>\n",
       "      <td>0.024 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.622472</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.621429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2017-07-30 14:06:10</td>\n",
       "      <td>2.025 sec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.802950</td>\n",
       "      <td>1.633685</td>\n",
       "      <td>0.259722</td>\n",
       "      <td>0.803065</td>\n",
       "      <td>1.634374</td>\n",
       "      <td>0.262330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2017-07-30 14:06:12</td>\n",
       "      <td>3.530 sec</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.756429</td>\n",
       "      <td>1.432764</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.756669</td>\n",
       "      <td>1.433968</td>\n",
       "      <td>0.258555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2017-07-30 14:06:17</td>\n",
       "      <td>8.371 sec</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.618091</td>\n",
       "      <td>1.002859</td>\n",
       "      <td>0.248803</td>\n",
       "      <td>0.618999</td>\n",
       "      <td>1.005871</td>\n",
       "      <td>0.249927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2017-07-30 14:06:24</td>\n",
       "      <td>15.443 sec</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.506408</td>\n",
       "      <td>0.739219</td>\n",
       "      <td>0.236480</td>\n",
       "      <td>0.508038</td>\n",
       "      <td>0.743431</td>\n",
       "      <td>0.238316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2017-07-30 14:06:36</td>\n",
       "      <td>27.299 sec</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.435449</td>\n",
       "      <td>0.581374</td>\n",
       "      <td>0.222369</td>\n",
       "      <td>0.437986</td>\n",
       "      <td>0.587285</td>\n",
       "      <td>0.225612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2017-07-30 14:06:58</td>\n",
       "      <td>49.566 sec</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.395780</td>\n",
       "      <td>0.492696</td>\n",
       "      <td>0.199911</td>\n",
       "      <td>0.399457</td>\n",
       "      <td>0.500608</td>\n",
       "      <td>0.204253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2017-07-30 14:07:23</td>\n",
       "      <td>1 min 14.844 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.378902</td>\n",
       "      <td>0.456017</td>\n",
       "      <td>0.185453</td>\n",
       "      <td>0.383381</td>\n",
       "      <td>0.465278</td>\n",
       "      <td>0.190281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp           duration  number_of_trees  training_rmse  \\\n",
       "0    2017-07-30 14:06:08          0.024 sec              0.0       0.857143   \n",
       "1    2017-07-30 14:06:10          2.025 sec              1.0       0.802950   \n",
       "2    2017-07-30 14:06:12          3.530 sec              2.0       0.756429   \n",
       "3    2017-07-30 14:06:17          8.371 sec              6.0       0.618091   \n",
       "4    2017-07-30 14:06:24         15.443 sec             12.0       0.506408   \n",
       "5    2017-07-30 14:06:36         27.299 sec             22.0       0.435449   \n",
       "6    2017-07-30 14:06:58         49.566 sec             37.0       0.395780   \n",
       "7    2017-07-30 14:07:23   1 min 14.844 sec             50.0       0.378902   \n",
       "\n",
       "   training_logloss  training_classification_error  validation_rmse  \\\n",
       "0          1.945910                       0.622472         0.857143   \n",
       "1          1.633685                       0.259722         0.803065   \n",
       "2          1.432764                       0.256757         0.756669   \n",
       "3          1.002859                       0.248803         0.618999   \n",
       "4          0.739219                       0.236480         0.508038   \n",
       "5          0.581374                       0.222369         0.437986   \n",
       "6          0.492696                       0.199911         0.399457   \n",
       "7          0.456017                       0.185453         0.383381   \n",
       "\n",
       "   validation_logloss  validation_classification_error  \n",
       "0            1.945910                         0.621429  \n",
       "1            1.634374                         0.262330  \n",
       "2            1.433968                         0.258555  \n",
       "3            1.005871                         0.249927  \n",
       "4            0.743431                         0.238316  \n",
       "5            0.587285                         0.225612  \n",
       "6            0.500608                         0.204253  \n",
       "7            0.465278                         0.190281  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "gbm_v1.score_history()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.8097192</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.983244</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9980606</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9996983</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9999828</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9999914</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.809719\n",
       "2    0.983244\n",
       "3    0.998061\n",
       "4    0.999698\n",
       "5    0.999983\n",
       "6    0.999991\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gbm_v1.hit_ratio_table(valid=True)\n",
    "\n",
    "\n",
    "# This default GBM is much worse than our original random forest.  \n",
    "# \n",
    "# \n",
    "# The GBM is far from converging, so there are three primary knobs to adjust to get our performance up if we want to keep a similar run time.  \n",
    "# \n",
    "# 1: Adding trees will help. The default is 50.  \n",
    "# 2: Increasing the learning rate will also help. The contribution of each tree will be stronger, so the model will move further away from the overall mean.  \n",
    "# 3: Increasing the depth will help. This is the parameter that is the least straightforward. Tuning trees and learning rate both have direct impact that is easy to understand. Changing the depth means you are adjusting the \"weakness\" of each learner. Adding depth makes each tree fit the data closer.  \n",
    "#   \n",
    "# The first configuration will attack depth the most, since we've seen the random forest focus on a continuous variable (elevation) and 40-class factor (soil type) the most.  \n",
    "# \n",
    "# Also we will take a look at how to review a model while it is running.  \n",
    "\n",
    "# ### GBM Round 2\n",
    "# \n",
    "# Let's do the following:\n",
    "# \n",
    "# 1. decrease the number of trees to speed up runtime(from default 50 to 20)\n",
    "# 2. increase the learning rate (from default 0.1 to 0.2)\n",
    "# 3. increase the depth (from default 5 to 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "gbm_v2 = H2OGradientBoostingEstimator(\n",
    "    ntrees=20,\n",
    "    learn_rate=0.2,\n",
    "    max_depth=10,\n",
    "    stopping_tolerance=0.01, #10-fold increase in threshold as defined in rf_v1\n",
    "    stopping_rounds=2,\n",
    "    score_each_iteration=True,\n",
    "    model_id=\"gbm_covType_v2\",\n",
    "    seed=2000000\n",
    ")\n",
    "gbm_v2.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)\n",
    "\n",
    "\n",
    "# ### Live Performance Monitoring\n",
    "# \n",
    "# While this is running, we can actually look at the model. To do this we simply need a new connection to H2O. \n",
    "# \n",
    "# This Python notebook will run the model, so we need either another notebook or the web browser (or R, etc.). In this demo, we will use [Flow](http://localhost:54321) in our web browser http://localhost:54321 and the focus will be to look at model performance, since we are using Python to control H2O. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9176852</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9969315</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9998535</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9999828</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.917685\n",
       "2    0.996932\n",
       "3    0.999853\n",
       "4    0.999983\n",
       "5    1\n",
       "6    1\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_v2.hit_ratio_table(valid=True)\n",
    "\n",
    "\n",
    "# This has moved us in the right direction, but still lower accuracy than the random forest.  \n",
    "# \n",
    "# It still has yet to converge, so we can make it more aggressive.  \n",
    "# \n",
    "# We can now add the stochastic nature of random forest into the GBM using some of the new H2O settings. This will help generalize and also provide a quicker runtime, so we can add a few more trees.\n",
    "\n",
    "# ### GBM: Third Time is the Charm\n",
    "# \n",
    "# 1. Add a few trees(from 20 to 30)\n",
    "# 2. Increase learning rate (to 0.3)\n",
    "# 3. Use a random 70% of rows to fit each tree\n",
    "# 4. Use a random 70% of columns to fit each tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_v3 = H2OGradientBoostingEstimator(\n",
    "    ntrees=30,\n",
    "    learn_rate=0.3,\n",
    "    max_depth=10,\n",
    "    sample_rate=0.7,\n",
    "    col_sample_rate=0.7,\n",
    "    stopping_rounds=2,\n",
    "    stopping_tolerance=0.01, #10-fold increase in threshold as defined in rf_v1\n",
    "    score_each_iteration=True,\n",
    "    model_id=\"gbm_covType_v3\",\n",
    "    seed=2000000\n",
    ")\n",
    "gbm_v3.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.943164</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9977245</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9998276</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9999828</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9999828</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9999828</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.943164\n",
       "2    0.997725\n",
       "3    0.999828\n",
       "4    0.999983\n",
       "5    0.999983\n",
       "6    0.999983\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_v3.hit_ratio_table(valid=True)\n",
    "\n",
    "\n",
    "# ### Parity\n",
    "# \n",
    "# Now the GBM is close to the initial random forest.\n",
    "# \n",
    "# However, we used a default random forest. Random forest's primary strength is how well it runs with standard parameters, and while there are only a few parameters to tune, we can experiment with those to see if it will make a difference.  \n",
    "# \n",
    "# The main parameters to tune are the tree depth and the mtries, which is the number of predictors to use.  \n",
    "# \n",
    "# The default depth of trees is 20. It is common to increase this number, to the point that in some implementations, the depth is unlimited. We will increase ours from 20 to 30.  \n",
    "# \n",
    "# Note that the default mtries depends on whether classification or regression is being run. The default for classification is one-third of the columns. The default for regression is the square root of the number of columns.  \n",
    "\n",
    "# ### Random Forest #2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "rf_v2 = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_covType_v2\",\n",
    "    ntrees=200,\n",
    "    max_depth=30,\n",
    "    stopping_rounds=2,\n",
    "    stopping_tolerance=0.01,\n",
    "    score_each_iteration=True,\n",
    "    seed=3000000)\n",
    "rf_v2.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9579375</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9971297</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9984916</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9985260</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9985347</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9985347</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9999999</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.957938\n",
       "2    0.99713\n",
       "3    0.998492\n",
       "4    0.998526\n",
       "5    0.998535\n",
       "6    0.998535\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_v2.hit_ratio_table(valid=True)\n",
    "\n",
    "\n",
    "# ### Final Predictions\n",
    "# \n",
    "# Now that we have our validation accuracy up beyond 95%, we can start considering our test data.  \n",
    "# We have withheld an extra test set to ensure that after all the parameter tuning we have repeatedly applied with the validation data, we still have a completely pristine data set upon which to test the predictive capacity of our model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#Excludes the \"Cover_Type\" column from the features provided\n",
    "final_rf_predictions = rf_v2.predict(test[:-1])\n",
    "\n",
    "\n",
    "# Technically, our model won't look at the [\"Cover_Type\"] column within the test data, as it is trained on a set of features not including \"Cover_Type\". It is up to the user whether to include it in the test frame provided for predictions, as it has no effect whatsoever.\n",
    "# \n",
    "# Let's take a peek at the first few rows of predictions returned by our model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">  class_1</th><th style=\"text-align: right;\">  class_2</th><th style=\"text-align: right;\">  class_3</th><th style=\"text-align: right;\">  class_4</th><th style=\"text-align: right;\">  class_5</th><th style=\"text-align: right;\">  class_6</th><th style=\"text-align: right;\">  class_7</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>class_2  </td><td style=\"text-align: right;\"> 0.3     </td><td style=\"text-align: right;\"> 0.7     </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\"> 0       </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>class_1  </td><td style=\"text-align: right;\"> 1       </td><td style=\"text-align: right;\"> 0       </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\"> 0       </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>class_1  </td><td style=\"text-align: right;\"> 0.777778</td><td style=\"text-align: right;\"> 0.222222</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\"> 0       </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>class_1  </td><td style=\"text-align: right;\"> 0.84507 </td><td style=\"text-align: right;\"> 0.15493 </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\"> 0       </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>class_2  </td><td style=\"text-align: right;\"> 0.205298</td><td style=\"text-align: right;\"> 0.794702</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\"> 0       </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>class_5  </td><td style=\"text-align: right;\"> 0       </td><td style=\"text-align: right;\"> 0.333333</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\"> 0.666667</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>class_1  </td><td style=\"text-align: right;\"> 1       </td><td style=\"text-align: right;\"> 0       </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\"> 0       </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>class_2  </td><td style=\"text-align: right;\"> 0.142857</td><td style=\"text-align: right;\"> 0.857143</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\"> 0       </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>class_2  </td><td style=\"text-align: right;\"> 0.192308</td><td style=\"text-align: right;\"> 0.807692</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\"> 0       </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>class_2  </td><td style=\"text-align: right;\"> 0       </td><td style=\"text-align: right;\"> 1       </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\"> 0       </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rf_predictions\n",
    "\n",
    "\n",
    "# Let's compare these predictions to the accuracy we got from our experimentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9579375</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9971297</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9984916</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9985260</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9985347</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9985347</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9999999</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.957938\n",
       "2    0.99713\n",
       "3    0.998492\n",
       "4    0.998526\n",
       "5    0.998535\n",
       "6    0.998535\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation set accuracy\n",
    "rf_v2.hit_ratio_table(valid=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict    0.957975\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test set accuracy\n",
    "(final_rf_predictions['predict']==test['Cover_Type']).as_data_frame(use_pandas=True).mean()\n",
    "\n",
    "\n",
    "# Our final error rates are very similar between validation and test sets. This suggests that we did not overfit the validation set during our experimentation. This concludes our demo of H2O GBM and H2O Random Forests.\n",
    "# \n",
    "# \n",
    "# ### Shut down the cluster\n",
    "# Shut down the cluster now that we are done using it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] in <ipython-input-23-06c455af4589> line 1:\n",
      "    >>> h2o.shutdown(prompt=False)\n",
      "        ^^^^ Deprecated, use ``h2o.cluster().shutdown()``.\n",
      "H2O session _sid_9e38 closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.shutdown(prompt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
